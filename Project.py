# -*- coding: utf-8 -*-
"""Yolo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t9V4n9gApPcg4wv7Gh78kk4v12U_9nbW
"""

!pip install ultralytics
print("âœ… Installed!")

from ultralytics import YOLO
import matplotlib.pyplot as plt
print("âœ… Imported!")

model = YOLO("yolov8n.pt")
print("âœ… Loaded!")
print(f"Model name: yolov8n")

!wget https://ultralytics.com/images/bus.jpg -q

print("âœ… Image downloaded: bus.jpg")

results = model.predict('bus.jpg')
results[0].show()
print('âœ… Detection done!')

# Let's see WHAT YOLO detected (like checking y_pred values)
results = model.predict('bus.jpg')
# Loop through all detections (like for loop in your code)
for box in results[0].boxes:
    # Get class ID (0=person, 5=bus, 2=car, etc.)
    class_id = int(box.cls[0])
    # Get class name (person, bus, car, etc.)
    class_name = results[0].names[class_id]
    # Get confidence (like accuracy, 0 to 1)
    confidence = float(box.conf[0])
    # Print (like you print accuracy)
    print(f"Detected: {class_name} - Confidence: {confidence:.2f}")

print("\nâœ… Total detections:", len(results[0].boxes))

# Detect ONLY people (filter others)

results = model.predict('bus.jpg')

people_count = 0

for box in results[0].boxes:

    class_id = int(box.cls[0])

    # Check: Is it a person? (class_id = 0)
    if class_id == 0:

        confidence = float(box.conf[0])

        # Only show if confidence > 50%
        if confidence > 0.5:
            people_count += 1
            print(f"Person {people_count} - Confidence: {confidence:.2f}")

print(f"\nâœ… Total PEOPLE detected: {people_count}")

from google.colab import files

print("ðŸ‘‡ Click 'Choose Files' and upload a crowd photo:")
uploaded = files.upload()

image_name = list(uploaded.keys())[0]
print(f"\nâœ… Uploaded: {image_name}")

# Detect people in  uploaded image

results = model.predict(image_name)

people_count = 0

for box in results[0].boxes:

    class_id = int(box.cls[0])

    # Only people (class_id = 0)
    if class_id == 0:

        confidence = float(box.conf[0])

        # Only if confidence > 50%
        if confidence > 0.5:
            people_count += 1
            print(f"Person {people_count} - Confidence: {confidence:.2f}")

print(f"\nâœ… Total PEOPLE in your image: {people_count}")

# Show image with boxes
results[0].show()

# Download a SHORT crowd video (only few seconds)
!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/people.mp4 -q

print("âœ… Short video downloaded: people.mp4")

from google.colab import files

# Upload video from your computer
print("ðŸ‘‡ Click 'Choose Files' and upload a SHORT video (5-10 sec max):")
uploaded = files.upload()

# Get filename
video_name = list(uploaded.keys())[0]
print(f"\nâœ… Uploaded: {video_name}")

import cv2

# Open your video
video = cv2.VideoCapture(video_name)

frame_count = 0
total_detections = 0

print("ðŸŽ¥ Processing your video...\n")

# Read frame by frame
while True:

    ret, frame = video.read()

    if not ret:
        break

    frame_count += 1

    # Detect people in THIS frame
    results = model.predict(frame, verbose=False)

    people_in_frame = 0

    for box in results[0].boxes:
        class_id = int(box.cls[0])

        if class_id == 0:  # Person
            confidence = float(box.conf[0])
            if confidence > 0.5:
                people_in_frame += 1

    total_detections += people_in_frame

    # Print every 10 frames
    if frame_count % 10 == 0:
        print(f"Frame {frame_count}: {people_in_frame} people")

video.release()

print(f"\nâœ… Processed {frame_count} frames")
print(f"âœ… Total detections: {total_detections}")
print(f"âœ… Average people per frame: {total_detections/frame_count:.1f}")

# Install a working SORT implementation
!pip install filterpy scikit-learn

print("âœ… Libraries installed!")

import numpy as np
from scipy.optimize import linear_sum_assignment

class SimpleTracker:
    """
    Simple tracking - like matching people across frames
    """

    def __init__(self):
        self.next_id = 1  # Start IDs from 1
        self.tracks = {}  # Store active tracks

    def iou(self, box1, box2):
        """
        Calculate overlap between two boxes (IoU = Intersection over Union)
        box format: [x1, y1, x2, y2]
        """
        # Get intersection coordinates
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])

        # Calculate intersection area
        intersection = max(0, x2 - x1) * max(0, y2 - y1)

        # Calculate union area
        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])
        union = area1 + area2 - intersection

        # Return IoU (0 to 1)
        if union == 0:
            return 0
        return intersection / union

    def update(self, detections):
        """
        Update tracks with new detections
        detections: list of [x1, y1, x2, y2, confidence]
        Returns: list of [x1, y1, x2, y2, track_id]
        """
        tracked_objects = []

        # If no previous tracks, create new ones
        if len(self.tracks) == 0:
            for det in detections:
                self.tracks[self.next_id] = det[:4]  # Store box
                tracked_objects.append(det[:4] + [self.next_id])
                self.next_id += 1
            return tracked_objects

        # Match detections to existing tracks
        track_ids = list(self.tracks.keys())
        track_boxes = list(self.tracks.values())

        # Calculate IoU between all detections and tracks
        iou_matrix = np.zeros((len(detections), len(track_ids)))

        for i, det in enumerate(detections):
            for j, track_box in enumerate(track_boxes):
                iou_matrix[i, j] = self.iou(det[:4], track_box)

        # Match using Hungarian algorithm
        if len(detections) > 0 and len(track_ids) > 0:
            row_ind, col_ind = linear_sum_assignment(-iou_matrix)

            matched_detections = set()
            matched_tracks = set()

            # Update matched tracks
            for i, j in zip(row_ind, col_ind):
                if iou_matrix[i, j] > 0.3:  # Threshold
                    track_id = track_ids[j]
                    self.tracks[track_id] = detections[i][:4]
                    tracked_objects.append(detections[i][:4] + [track_id])
                    matched_detections.add(i)
                    matched_tracks.add(j)

            # Create new tracks for unmatched detections
            for i, det in enumerate(detections):
                if i not in matched_detections:
                    self.tracks[self.next_id] = det[:4]
                    tracked_objects.append(det[:4] + [self.next_id])
                    self.next_id += 1

            # Remove unmatched tracks (people who left)
            for j, track_id in enumerate(track_ids):
                if j not in matched_tracks:
                    del self.tracks[track_id]

        return tracked_objects

# Create tracker
tracker = SimpleTracker()

print("âœ… Simple Tracker created!")
print("This tracker will give each person a unique ID")

import cv2

# Open your video again
video = cv2.VideoCapture(video_name)

# Create NEW tracker (reset IDs)
tracker = SimpleTracker()

frame_count = 0
active_ids = set()  # Store all IDs seen

print("ðŸŽ¥ Processing with TRACKING...\n")

while True:

    ret, frame = video.read()

    if not ret:
        break

    frame_count += 1

    # Step 1: DETECT people with YOLO
    results = model.predict(frame, verbose=False)

    detections = []
    for box in results[0].boxes:
        class_id = int(box.cls[0])

        if class_id == 0:  # Person only
            confidence = float(box.conf[0])
            if confidence > 0.5:
                x1, y1, x2, y2 = box.xyxy[0]
                detections.append([float(x1), float(y1), float(x2), float(y2), confidence])

    # Step 2: TRACK people (assign IDs)
    tracked = tracker.update(detections)

    # Collect IDs
    for obj in tracked:
        active_ids.add(int(obj[4]))

    # Print every 10 frames
    if frame_count % 10 == 0:
        print(f"Frame {frame_count}: {len(tracked)} people tracked, Active IDs: {len(active_ids)}")

video.release()

print(f"\nâœ… Processed {frame_count} frames")
print(f"âœ… Total unique people tracked: {len(active_ids)}")
print(f"âœ… IDs used: {sorted(active_ids)}")

import cv2
from google.colab.patches import cv2_imshow
import numpy as np

# Open video
video = cv2.VideoCapture(video_name)

# Get video properties
fps = int(video.get(cv2.CAP_PROP_FPS))
width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))

# Create video writer
output_path = 'tracked_output.mp4'
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))

# Create NEW tracker
tracker = SimpleTracker()

frame_count = 0
total_unique_ids = set()

print("ðŸŽ¥ Creating output video with tracking...\n")

while True:
    ret, frame = video.read()

    if not ret:
        break

    frame_count += 1

    # Detect people
    results = model.predict(frame, verbose=False)

    detections = []
    for box in results[0].boxes:
        class_id = int(box.cls[0])
        if class_id == 0:
            confidence = float(box.conf[0])
            if confidence > 0.5:
                x1, y1, x2, y2 = box.xyxy[0]
                detections.append([float(x1), float(y1), float(x2), float(y2), confidence])

    # Track people
    tracked = tracker.update(detections)

    # Draw boxes and IDs on frame
    for obj in tracked:
        x1, y1, x2, y2, track_id = obj
        track_id = int(track_id)
        total_unique_ids.add(track_id)

        # Draw rectangle
        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

        # Draw ID
        label = f"ID: {track_id}"
        cv2.putText(frame, label, (int(x1), int(y1)-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # Add frame info
    info_text = f"Frame: {frame_count} | People: {len(tracked)}"
    cv2.putText(frame, info_text, (10, 30),
               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

    # Write frame
    out.write(frame)

    if frame_count % 30 == 0:
        print(f"Processed {frame_count} frames...")

video.release()
out.release()

print(f"\nâœ… Output video saved: {output_path}")
print(f"âœ… Total frames: {frame_count}")
print(f"âœ… Total unique IDs: {len(total_unique_ids)}")

# Download the output video
from google.colab import files
files.download(output_path)
print("\nðŸ“¥ Downloading output video...")